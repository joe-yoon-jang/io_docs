---
layout: post
title: LLM 응용을 위한 LangChain
parent: LangChain
has_children: fale
nav_order: 1
---

# LLM 응용을 위한 LangChain

- LangChain 이 어떻게 작동하는지 이해하는데 중요한 개념으로서 체인(chain) 액션플랜생성(action plan generation) 그리고 메모리 등이 있다

## 확률적 앵무새(stochastic parrots)를 넘어서

- 언어적으로 설득력 있는 문장을 생성할 수 있지만 단어 뒤의 의미를 실제로 이해하지 못하는 LLM을 말한다
- 단순히 연산자원과 데이터 규모를 확장하는 것만으로는 추론 능력이나 상식이 부여되진 않음
- 프로프팅, 사고체인(chain of thought) 추론, 검색기반의 근거화(retrieval grounding) 등 기술이 모델 훈련에 필요

## LLM의 한계는 무엇인가?

- LLM의 고민
  - 오래된 지식: 훈련 데이터에 의존. 외부 통합이 없으면 최근의 실세계 정보 제공할 수 없다
  - 행동불가능성: LLM은 검색 계산 또는 조회와 같은 상호 작용적인 작업을 수행 불가
  - 맥락부족: 이전 대화와 일관된 응답 및 보충적인 세보정보 관련 맥락 통합에 단점
  - 환각 위험: 부정확하거나 비논리적인 대답
  - 편향 및 차별: 훈련된 데이터에 따라 종교적 이념적 또는 정치적 성향의 편향을 보일수있음
  - 투명성 부족: 행동이 불투명하고 해석이 어렵게 될수있음
  - 맥락 부족: 태화에서 맥락을 이해하고 통합하는 데 어려움

## LLM의 환계를 완화하는 방법
- 검색 증강(retrieval augmentation): 외부 컨텍스트를 제공하고 환각의 위험을 줄인다
- 체이닝(chaining): 검색과 계산과 같은 동작을 통합
- 프롬프트 공학(prompt engineering): 주요 컨텍스트를 제공해 적절한 응답을 가이드하는 프롬프트
- 모니터링 필터링 및 리뷰:
  - 금지된 단어 필터와 같은 필터
  - 헌법원칙
  - 인간 리뷰로 모델의 동작과 출력에 대한 통찰력 제공
- 메모리: 대화 데이터와 컨텍스트를 꾸준히 유지해 상호 작용 사이에서 대화 문맥을 유지
- 미세조정: 애플리케이션 도메인 및 원칙에 더 적절한 데이터로 LLM을 훈련하고 조정
- 파이프라인
  - 구성성 능력의 간극을 극복하기 위해서 명시적인 기술인 앨리시트 프롬프팅(elicit prompting)과 사고 체인 추론과 같은 기술사용
  - 자기질문 프롬프팅(self-ask prompting)과 같은 방법은 문제를 체계적으로 분해 및 결함을 완화
  - 위에 도구를 파이프라인에 통합하여 부족한 능력을 해결
  - 프롬프팅은 맥락을 제공, 체이닝은 추론단계를 제공, 검색은 사실을 통합

## LLM 응용이란 무엇인가?

- 클라이언트 